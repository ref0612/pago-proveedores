{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dc4131a",
   "metadata": {},
   "source": [
    "# Validación, Normalización y Match de Zonas en CSV\n",
    "\n",
    "Este notebook permite validar, limpiar y normalizar los datos de origen y destino de un archivo CSV, y realizar el match correcto con la zona correspondiente. El objetivo es asegurar que los datos estén listos para ser importados al backend sin errores de codificación ni de matching.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Importar librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd33f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import os\n",
    "\n",
    "# Opcional: para warnings y display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de display\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfb54fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo CSV a validar\n",
    "csv_path = r'C:\\Users\\ferna\\Downloads\\este es el que hay que subir.csv'\n",
    "\n",
    "# Intentar cargar el archivo con encoding utf-8, fallback a latin1 si falla\n",
    "try:\n",
    "    df = pd.read_csv(csv_path, encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(csv_path, encoding='latin1')\n",
    "\n",
    "print(f\"Archivo cargado: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c26624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar las primeras filas para inspeccionar la estructura y los datos\n",
    "print(f\"Filas: {df.shape[0]}, Columnas: {df.shape[1]}\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080d5178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validar estructura y contenido del archivo\n",
    "required_columns = ['origen', 'destino', 'zona']\n",
    "missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "\n",
    "if missing_cols:\n",
    "    print(f\"Faltan columnas requeridas: {missing_cols}\")\n",
    "else:\n",
    "    print(\"Todas las columnas requeridas están presentes.\")\n",
    "\n",
    "# Revisar nulos y valores únicos\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "print(df[required_columns].isnull().sum())\n",
    "\n",
    "print(\"\\nValores únicos por columna:\")\n",
    "for col in required_columns:\n",
    "    print(f\"{col}: {df[col].nunique()} únicos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b2ba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de normalización robusta\n",
    "import re\n",
    "def normalize_str(s):\n",
    "    if pd.isnull(s):\n",
    "        return ''\n",
    "    s = str(s).strip().lower()\n",
    "    s = s.replace('ñ', 'n')\n",
    "    s = unicodedata.normalize('NFD', s)\n",
    "    s = ''.join(c for c in s if unicodedata.category(c) != 'Mn')\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    return s\n",
    "\n",
    "# Aplicar normalización a columnas de origen y destino\n",
    "df['origen_norm'] = df['origen'].apply(normalize_str)\n",
    "df['destino_norm'] = df['destino'].apply(normalize_str)\n",
    "\n",
    "print(\"Ejemplo de normalización:\")\n",
    "df[['origen', 'origen_norm', 'destino', 'destino_norm']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78839bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear catálogo de zonas normalizadas\n",
    "zonas_catalogo = df[['zona']].drop_duplicates().copy()\n",
    "zonas_catalogo['zona_norm'] = zonas_catalogo['zona'].apply(normalize_str)\n",
    "\n",
    "# Diccionario para match rápido\n",
    "zona_map = dict(zip(zonas_catalogo['zona_norm'], zonas_catalogo['zona']))\n",
    "\n",
    "# Normalizar zona en el dataframe principal\n",
    "df['zona_norm'] = df['zona'].apply(normalize_str)\n",
    "\n",
    "# Asignar zona original a cada fila según zona normalizada (puede usarse para validación cruzada)\n",
    "df['zona_match'] = df['zona_norm'].map(zona_map)\n",
    "\n",
    "# Mostrar posibles problemas de matching\n",
    "problemas = df[df['zona_match'].isnull() | (df['zona'] != df['zona_match'])]\n",
    "if not problemas.empty:\n",
    "    print('Filas con problemas de matching de zona:')\n",
    "    display(problemas[['origen', 'destino', 'zona', 'zona_norm', 'zona_match']].head(20))\n",
    "else:\n",
    "    print('Todas las zonas fueron correctamente normalizadas y matcheadas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dead330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resultados finales: origen/destino/zona normalizados y zona asignada\n",
    "cols = ['origen', 'origen_norm', 'destino', 'destino_norm', 'zona', 'zona_norm', 'zona_match']\n",
    "df[cols].head(20)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
